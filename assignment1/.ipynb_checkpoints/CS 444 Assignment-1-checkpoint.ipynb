{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_process import get_FASHION_data, get_RICE_data\n",
    "from scipy.spatial import distance\n",
    "from models import Perceptron, SVM, Softmax, Logistic\n",
    "from kaggle_submission import output_submission_csv\n",
    "%matplotlib inline\n",
    "\n",
    "# For auto-reloading external modules\n",
    "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we determine the number of images for each split and load the images.\n",
    "<br /> \n",
    "TRAIN_IMAGES + VAL_IMAGES = (0, 60000]\n",
    ", TEST_IMAGES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change these numbers for experimentation\n",
    "# For submission we will use the default values \n",
    "TRAIN_IMAGES = 50000\n",
    "VAL_IMAGES = 10000\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_FASHION_data(TRAIN_IMAGES, VAL_IMAGES, normalize=normalize)\n",
    "X_train_fashion, y_train_fashion = data['X_train'], data['y_train']\n",
    "X_val_fashion, y_val_fashion = data['X_val'], data['y_val']\n",
    "X_test_fashion, y_test_fashion = data['X_test'], data['y_test']\n",
    "n_class_fashion = len(np.unique(y_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  10911\n",
      "Number of val samples:  3637\n",
      "Number of test samples:  3637\n"
     ]
    }
   ],
   "source": [
    "# loads train / test / val splits of 80%, 20%, 20% \n",
    "data = get_RICE_data()\n",
    "X_train_RICE, y_train_RICE = data['X_train'], data['y_train']\n",
    "X_val_RICE, y_val_RICE = data['X_val'], data['y_val']\n",
    "X_test_RICE, y_test_RICE = data['X_test'], data['y_test']\n",
    "n_class_RICE = len(np.unique(y_test_RICE))\n",
    "\n",
    "print(\"Number of train samples: \", X_train_RICE.shape[0])\n",
    "print(\"Number of val samples: \", X_val_RICE.shape[0])\n",
    "print(\"Number of test samples: \", X_test_RICE.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes how well your model performs using accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, y_test):\n",
    "    return np.sum(y_test == pred) / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according to the perceptron update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Perceptron classifier in the **models/perceptron.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Perceptron classifier class \n",
    "- The train function of the Perceptron class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 6.948\n",
      "Epoch 1 Accuracy 80.778\n",
      "Epoch 2 Accuracy 78.302\n",
      "Epoch 3 Accuracy 80.42399999999999\n",
      "Epoch 4 Accuracy 81.42399999999999\n",
      "Epoch 5 Accuracy 83.298\n",
      "Epoch 6 Accuracy 83.55\n",
      "Epoch 7 Accuracy 84.078\n",
      "Epoch 8 Accuracy 83.082\n",
      "Epoch 9 Accuracy 83.50800000000001\n",
      "Epoch 10 Accuracy 82.87400000000001\n",
      "Epoch 11 Accuracy 82.77799999999999\n",
      "Epoch 12 Accuracy 83.6\n",
      "Epoch 13 Accuracy 82.896\n",
      "Epoch 14 Accuracy 82.446\n",
      "Epoch 15 Accuracy 83.738\n",
      "Epoch 16 Accuracy 81.104\n",
      "Epoch 17 Accuracy 83.174\n",
      "Epoch 18 Accuracy 83.562\n",
      "Epoch 19 Accuracy 83.658\n",
      "Epoch 20 Accuracy 83.646\n",
      "Epoch 21 Accuracy 84.17999999999999\n",
      "Epoch 22 Accuracy 84.19\n",
      "Epoch 23 Accuracy 83.932\n",
      "Epoch 24 Accuracy 83.768\n",
      "Epoch 25 Accuracy 84.858\n",
      "Epoch 26 Accuracy 84.084\n",
      "Epoch 27 Accuracy 83.788\n",
      "Epoch 28 Accuracy 84.97200000000001\n",
      "Epoch 29 Accuracy 84.664\n",
      "Epoch 30 Accuracy 84.82\n",
      "Epoch 31 Accuracy 84.958\n",
      "Epoch 32 Accuracy 84.822\n",
      "Epoch 33 Accuracy 84.94\n",
      "Epoch 34 Accuracy 84.672\n",
      "Epoch 35 Accuracy 84.634\n",
      "Epoch 36 Accuracy 84.858\n",
      "Epoch 37 Accuracy 84.80799999999999\n",
      "Epoch 38 Accuracy 84.734\n",
      "Epoch 39 Accuracy 84.758\n",
      "Epoch 40 Accuracy 84.82\n",
      "Epoch 41 Accuracy 84.812\n",
      "Epoch 42 Accuracy 84.83800000000001\n",
      "Epoch 43 Accuracy 84.81400000000001\n",
      "Epoch 44 Accuracy 84.858\n",
      "Epoch 45 Accuracy 84.764\n",
      "Epoch 46 Accuracy 84.82600000000001\n",
      "Epoch 47 Accuracy 84.792\n",
      "Epoch 48 Accuracy 84.768\n",
      "Epoch 49 Accuracy 84.796\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "n_epochs = 50\n",
    "\n",
    "percept_fashion = Perceptron(n_class_fashion, lr, n_epochs)\n",
    "percept_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 84.800000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 80.210000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 79.710000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy, output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/perceptron_submission_fashion.csv', percept_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 54.779580240124645\n",
      "Epoch 1 Accuracy 71.6524608193566\n",
      "Epoch 2 Accuracy 58.042342590046744\n",
      "Epoch 3 Accuracy 54.90789111905416\n",
      "Epoch 4 Accuracy 90.50499495921547\n",
      "Epoch 5 Accuracy 54.779580240124645\n",
      "Epoch 6 Accuracy 98.86353221519568\n",
      "Epoch 7 Accuracy 98.92768765466043\n",
      "Epoch 8 Accuracy 99.78920355604436\n",
      "Epoch 9 Accuracy 94.51929245715334\n",
      "Epoch 10 Accuracy 99.84419393272844\n",
      "Epoch 11 Accuracy 99.88085418385117\n",
      "Epoch 12 Accuracy 99.89918430941252\n",
      "Epoch 13 Accuracy 99.26679497754559\n",
      "Epoch 14 Accuracy 99.83502886994776\n",
      "Epoch 15 Accuracy 99.87168912107049\n",
      "Epoch 16 Accuracy 99.83502886994776\n",
      "Epoch 17 Accuracy 99.83502886994776\n",
      "Epoch 18 Accuracy 99.86252405828981\n",
      "Epoch 19 Accuracy 99.93584456053523\n",
      "Epoch 20 Accuracy 99.88085418385117\n",
      "Epoch 21 Accuracy 99.89001924663185\n",
      "Epoch 22 Accuracy 99.88085418385117\n",
      "Epoch 23 Accuracy 99.92667949775455\n",
      "Epoch 24 Accuracy 99.93584456053523\n",
      "Epoch 25 Accuracy 99.93584456053523\n",
      "Epoch 26 Accuracy 99.84419393272844\n",
      "Epoch 27 Accuracy 99.91751443497388\n",
      "Epoch 28 Accuracy 99.91751443497388\n",
      "Epoch 29 Accuracy 99.91751443497388\n",
      "Epoch 30 Accuracy 99.89918430941252\n",
      "Epoch 31 Accuracy 99.93584456053523\n",
      "Epoch 32 Accuracy 99.93584456053523\n",
      "Epoch 33 Accuracy 99.93584456053523\n",
      "Epoch 34 Accuracy 99.91751443497388\n",
      "Epoch 35 Accuracy 99.92667949775455\n",
      "Epoch 36 Accuracy 99.93584456053523\n",
      "Epoch 37 Accuracy 99.92667949775455\n",
      "Epoch 38 Accuracy 99.93584456053523\n",
      "Epoch 39 Accuracy 99.93584456053523\n",
      "Epoch 40 Accuracy 99.93584456053523\n",
      "Epoch 41 Accuracy 99.93584456053523\n",
      "Epoch 42 Accuracy 99.93584456053523\n",
      "Epoch 43 Accuracy 99.93584456053523\n",
      "Epoch 44 Accuracy 99.93584456053523\n",
      "Epoch 45 Accuracy 99.93584456053523\n",
      "Epoch 46 Accuracy 99.93584456053523\n",
      "Epoch 47 Accuracy 99.93584456053523\n",
      "Epoch 48 Accuracy 99.92667949775455\n",
      "Epoch 49 Accuracy 99.92667949775455\n",
      "Epoch 50 Accuracy 99.93584456053523\n",
      "Epoch 51 Accuracy 99.92667949775455\n",
      "Epoch 52 Accuracy 99.92667949775455\n",
      "Epoch 53 Accuracy 99.93584456053523\n",
      "Epoch 54 Accuracy 99.92667949775455\n",
      "Epoch 55 Accuracy 99.93584456053523\n",
      "Epoch 56 Accuracy 99.93584456053523\n",
      "Epoch 57 Accuracy 99.93584456053523\n",
      "Epoch 58 Accuracy 99.93584456053523\n",
      "Epoch 59 Accuracy 99.93584456053523\n",
      "Epoch 60 Accuracy 99.93584456053523\n",
      "Epoch 61 Accuracy 99.93584456053523\n",
      "Epoch 62 Accuracy 99.93584456053523\n",
      "Epoch 63 Accuracy 99.93584456053523\n",
      "Epoch 64 Accuracy 99.93584456053523\n",
      "Epoch 65 Accuracy 99.93584456053523\n",
      "Epoch 66 Accuracy 99.93584456053523\n",
      "Epoch 67 Accuracy 99.93584456053523\n",
      "Epoch 68 Accuracy 99.93584456053523\n",
      "Epoch 69 Accuracy 99.93584456053523\n",
      "Epoch 70 Accuracy 99.93584456053523\n",
      "Epoch 71 Accuracy 99.93584456053523\n",
      "Epoch 72 Accuracy 99.93584456053523\n",
      "Epoch 73 Accuracy 99.93584456053523\n",
      "Epoch 74 Accuracy 99.93584456053523\n",
      "Epoch 75 Accuracy 99.93584456053523\n",
      "Epoch 76 Accuracy 99.93584456053523\n",
      "Epoch 77 Accuracy 99.93584456053523\n",
      "Epoch 78 Accuracy 99.93584456053523\n",
      "Epoch 79 Accuracy 99.93584456053523\n",
      "Epoch 80 Accuracy 99.93584456053523\n",
      "Epoch 81 Accuracy 99.93584456053523\n",
      "Epoch 82 Accuracy 99.93584456053523\n",
      "Epoch 83 Accuracy 99.93584456053523\n",
      "Epoch 84 Accuracy 99.93584456053523\n",
      "Epoch 85 Accuracy 99.93584456053523\n",
      "Epoch 86 Accuracy 99.93584456053523\n",
      "Epoch 87 Accuracy 99.93584456053523\n",
      "Epoch 88 Accuracy 99.93584456053523\n",
      "Epoch 89 Accuracy 99.93584456053523\n",
      "Epoch 90 Accuracy 99.93584456053523\n",
      "Epoch 91 Accuracy 99.93584456053523\n",
      "Epoch 92 Accuracy 99.93584456053523\n",
      "Epoch 93 Accuracy 99.93584456053523\n",
      "Epoch 94 Accuracy 99.93584456053523\n",
      "Epoch 95 Accuracy 99.93584456053523\n",
      "Epoch 96 Accuracy 99.93584456053523\n",
      "Epoch 97 Accuracy 99.93584456053523\n",
      "Epoch 98 Accuracy 99.93584456053523\n",
      "Epoch 99 Accuracy 99.93584456053523\n"
     ]
    }
   ],
   "source": [
    "lr = 0.3\n",
    "n_epochs = 100\n",
    "\n",
    "percept_RICE = Perceptron(n_class_RICE, lr, n_epochs)\n",
    "percept_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 99.935845\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 99.917514\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 99.917514\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will implement a \"soft margin\" SVM. In this formulation you will maximize the margin between positive and negative training examples and penalize margin violations using a hinge loss.\n",
    "\n",
    "We will optimize the SVM loss using SGD. This means you must compute the loss function with respect to model weights. You will use this gradient to update the model weights.\n",
    "\n",
    "SVM optimized with SGD has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Epochs** - similar to as defined above in Perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case it is a coefficient on the term which maximizes the margin. You could try different values. The default value is set to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the SVM using SGD in the **models/svm.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the SVM classifier class \n",
    "- The train function of the SVM class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 10.91\n",
      "Epoch 1 Accuracy 76.776\n",
      "Epoch 2 Accuracy 79.252\n",
      "Epoch 3 Accuracy 80.054\n",
      "Epoch 4 Accuracy 81.17\n",
      "Epoch 5 Accuracy 83.94\n",
      "Epoch 6 Accuracy 83.538\n",
      "Epoch 7 Accuracy 84.048\n",
      "Epoch 8 Accuracy 84.39999999999999\n",
      "Epoch 9 Accuracy 84.2\n",
      "Epoch 10 Accuracy 84.446\n",
      "Epoch 11 Accuracy 84.37\n",
      "Epoch 12 Accuracy 84.36\n",
      "Epoch 13 Accuracy 84.304\n",
      "Epoch 14 Accuracy 84.39\n",
      "Epoch 15 Accuracy 84.406\n",
      "Epoch 16 Accuracy 84.348\n",
      "Epoch 17 Accuracy 84.36399999999999\n",
      "Epoch 18 Accuracy 84.414\n",
      "Epoch 19 Accuracy 84.392\n",
      "Epoch 20 Accuracy 84.396\n",
      "Epoch 21 Accuracy 84.422\n",
      "Epoch 22 Accuracy 84.402\n",
      "Epoch 23 Accuracy 84.39999999999999\n",
      "Epoch 24 Accuracy 84.39999999999999\n",
      "Epoch 25 Accuracy 84.396\n",
      "Epoch 26 Accuracy 84.398\n",
      "Epoch 27 Accuracy 84.396\n",
      "Epoch 28 Accuracy 84.39999999999999\n",
      "Epoch 29 Accuracy 84.404\n",
      "Epoch 30 Accuracy 84.402\n",
      "Epoch 31 Accuracy 84.39999999999999\n",
      "Epoch 32 Accuracy 84.39999999999999\n",
      "Epoch 33 Accuracy 84.39999999999999\n",
      "Epoch 34 Accuracy 84.39999999999999\n",
      "Epoch 35 Accuracy 84.39999999999999\n",
      "Epoch 36 Accuracy 84.39999999999999\n",
      "Epoch 37 Accuracy 84.39999999999999\n",
      "Epoch 38 Accuracy 84.39999999999999\n",
      "Epoch 39 Accuracy 84.39999999999999\n",
      "Epoch 40 Accuracy 84.39999999999999\n",
      "Epoch 41 Accuracy 84.39999999999999\n",
      "Epoch 42 Accuracy 84.39999999999999\n",
      "Epoch 43 Accuracy 84.39999999999999\n",
      "Epoch 44 Accuracy 84.39999999999999\n",
      "Epoch 45 Accuracy 84.39999999999999\n",
      "Epoch 46 Accuracy 84.39999999999999\n",
      "Epoch 47 Accuracy 84.39999999999999\n",
      "Epoch 48 Accuracy 84.39999999999999\n",
      "Epoch 49 Accuracy 84.39999999999999\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "n_epochs = 50\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_fashion = SVM(n_class_fashion, lr, n_epochs, reg_const)\n",
    "svm_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 84.400000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 82.740000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 82.310000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/svm_submission_fashion.csv', svm_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 54.779580240124645\n",
      "Epoch 1 Accuracy 55.77857208321877\n",
      "Epoch 2 Accuracy 72.75226835303822\n",
      "Epoch 3 Accuracy 75.0985244248923\n",
      "Epoch 4 Accuracy 78.97534598111997\n",
      "Epoch 5 Accuracy 78.85620016497114\n",
      "Epoch 6 Accuracy 78.75538447438365\n",
      "Epoch 7 Accuracy 79.14948217395289\n",
      "Epoch 8 Accuracy 78.7278892860416\n",
      "Epoch 9 Accuracy 78.67289890935753\n",
      "Epoch 10 Accuracy 78.99367610668133\n",
      "Epoch 11 Accuracy 79.0120062322427\n",
      "Epoch 12 Accuracy 79.14031711117221\n",
      "Epoch 13 Accuracy 78.87453029053249\n",
      "Epoch 14 Accuracy 79.04866648336541\n",
      "Epoch 15 Accuracy 79.0120062322427\n",
      "Epoch 16 Accuracy 79.04866648336541\n",
      "Epoch 17 Accuracy 79.02117129502338\n",
      "Epoch 18 Accuracy 79.04866648336541\n",
      "Epoch 19 Accuracy 79.03033635780406\n",
      "Epoch 20 Accuracy 79.05783154614609\n",
      "Epoch 21 Accuracy 79.04866648336541\n",
      "Epoch 22 Accuracy 79.03950142058474\n",
      "Epoch 23 Accuracy 79.05783154614609\n",
      "Epoch 24 Accuracy 79.05783154614609\n",
      "Epoch 25 Accuracy 79.05783154614609\n",
      "Epoch 26 Accuracy 79.05783154614609\n",
      "Epoch 27 Accuracy 79.05783154614609\n",
      "Epoch 28 Accuracy 79.05783154614609\n",
      "Epoch 29 Accuracy 79.05783154614609\n",
      "Epoch 30 Accuracy 79.05783154614609\n",
      "Epoch 31 Accuracy 79.05783154614609\n",
      "Epoch 32 Accuracy 79.05783154614609\n",
      "Epoch 33 Accuracy 79.05783154614609\n",
      "Epoch 34 Accuracy 79.05783154614609\n",
      "Epoch 35 Accuracy 79.05783154614609\n",
      "Epoch 36 Accuracy 79.05783154614609\n",
      "Epoch 37 Accuracy 79.05783154614609\n",
      "Epoch 38 Accuracy 79.05783154614609\n",
      "Epoch 39 Accuracy 79.05783154614609\n",
      "Epoch 40 Accuracy 79.05783154614609\n",
      "Epoch 41 Accuracy 79.05783154614609\n",
      "Epoch 42 Accuracy 79.05783154614609\n",
      "Epoch 43 Accuracy 79.05783154614609\n",
      "Epoch 44 Accuracy 79.05783154614609\n",
      "Epoch 45 Accuracy 79.05783154614609\n",
      "Epoch 46 Accuracy 79.05783154614609\n",
      "Epoch 47 Accuracy 79.05783154614609\n",
      "Epoch 48 Accuracy 79.05783154614609\n",
      "Epoch 49 Accuracy 79.05783154614609\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "n_epochs = 50\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_RICE = SVM(n_class_RICE, lr, n_epochs, reg_const)\n",
    "svm_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 79.057832\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 78.608743\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 79.323618\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classifier (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, you will train a Softmax classifier. This classifier consists of a linear function of the input data followed by a softmax function which outputs a vector of dimension C (number of classes) for each data point. Each entry of the softmax output vector corresponds to a confidence in one of the C classes, and like a probability distribution, the entries of the output vector sum to 1. We use a cross-entropy loss on this sotmax output to train the model. \n",
    "\n",
    "Check the following link as an additional resource on softmax classification: http://cs231n.github.io/linear-classify/#softmax\n",
    "\n",
    "Once again we will train the classifier with SGD. This means you need to compute the gradients of the softmax cross-entropy loss function according to the weights and update the weights using this gradient. Check the following link to help with implementing the gradient updates: https://deepnotes.io/softmax-crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax classifier has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - As above, this controls how much the model weights are updated with respect to their gradient.\n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case, we minimize the L2 norm of the model weights as regularization, so the regularization constant is a coefficient on the L2 norm in the combined cross-entropy and regularization objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement a softmax classifier using SGD in the **models/softmax.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Softmax classifier class \n",
    "- The train function of the Softmax class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 12.076\n",
      "Epoch 1 Accuracy 81.382\n",
      "Epoch 2 Accuracy 70.86\n",
      "Epoch 3 Accuracy 79.062\n",
      "Epoch 4 Accuracy 79.214\n",
      "Epoch 5 Accuracy 76.168\n",
      "Epoch 6 Accuracy 80.49199999999999\n",
      "Epoch 7 Accuracy 79.318\n",
      "Epoch 8 Accuracy 80.866\n",
      "Epoch 9 Accuracy 77.64\n",
      "Epoch 10 Accuracy 80.116\n",
      "Epoch 11 Accuracy 82.902\n",
      "Epoch 12 Accuracy 81.306\n",
      "Epoch 13 Accuracy 84.652\n",
      "Epoch 14 Accuracy 80.952\n",
      "Epoch 15 Accuracy 84.512\n",
      "Epoch 16 Accuracy 85.858\n",
      "Epoch 17 Accuracy 84.49\n",
      "Epoch 18 Accuracy 83.212\n",
      "Epoch 19 Accuracy 82.74000000000001\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 20\n",
    "reg_const = 1\n",
    "\n",
    "softmax_fashion = Softmax(n_class_fashion, lr, n_epochs, reg_const)\n",
    "softmax_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 85.448000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 81.620000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 80.570000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/softmax_submission_fashion.csv', softmax_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 48.47401704701677\n",
      "Epoch 1 Accuracy 60.18696728072588\n",
      "Epoch 2 Accuracy 75.55677756392632\n",
      "Epoch 3 Accuracy 78.92035560443588\n",
      "Epoch 4 Accuracy 75.55677756392632\n",
      "Epoch 5 Accuracy 75.30932086884795\n",
      "Epoch 6 Accuracy 59.27962606543855\n",
      "Epoch 7 Accuracy 75.21767024104115\n",
      "Epoch 8 Accuracy 65.98845202089633\n",
      "Epoch 9 Accuracy 70.06690495829896\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "reg_const = 0.05\n",
    "\n",
    "softmax_RICE = Softmax(n_class_RICE, lr, n_epochs, reg_const)\n",
    "softmax_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 76.729906\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 75.996701\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 76.656585\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Classifier has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Threshold** - The decision boundary of the classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Logistic Classifier in the **models/logistic.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Logistic classifier class \n",
    "- The train function of the Logistic class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.2\n",
    "n_epochs = 100\n",
    "threshold = 0\n",
    "\n",
    "y_train_RICE = np.where(y_train_RICE == 0, -1, y_train_RICE)\n",
    "\n",
    "lr = Logistic(learning_rate, n_epochs, threshold)\n",
    "lr.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 99.853359\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 99.752543\n"
     ]
    }
   ],
   "source": [
    "y_val_RICE = np.where(y_val_RICE == 0, -1, y_val_RICE)\n",
    "pred_lr = lr.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 99.725048\n"
     ]
    }
   ],
   "source": [
    "y_test_RICE = np.where(y_test_RICE == 0, -1, y_test_RICE)\n",
    "pred_lr = lr.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
