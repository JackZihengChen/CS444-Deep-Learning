{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_process import get_FASHION_data, get_RICE_data\n",
    "from scipy.spatial import distance\n",
    "from models import Perceptron, SVM, Softmax, Logistic\n",
    "from kaggle_submission import output_submission_csv\n",
    "%matplotlib inline\n",
    "\n",
    "# For auto-reloading external modules\n",
    "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we determine the number of images for each split and load the images.\n",
    "<br /> \n",
    "TRAIN_IMAGES + VAL_IMAGES = (0, 60000]\n",
    ", TEST_IMAGES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change these numbers for experimentation\n",
    "# For submission we will use the default values \n",
    "TRAIN_IMAGES = 50000\n",
    "VAL_IMAGES = 10000\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_FASHION_data(TRAIN_IMAGES, VAL_IMAGES, normalize=normalize)\n",
    "X_train_fashion, y_train_fashion = data['X_train'], data['y_train']\n",
    "X_val_fashion, y_val_fashion = data['X_val'], data['y_val']\n",
    "X_test_fashion, y_test_fashion = data['X_test'], data['y_test']\n",
    "n_class_fashion = len(np.unique(y_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  10911\n",
      "Number of val samples:  3637\n",
      "Number of test samples:  3637\n"
     ]
    }
   ],
   "source": [
    "# loads train / test / val splits of 80%, 20%, 20% \n",
    "data = get_RICE_data()\n",
    "X_train_RICE, y_train_RICE = data['X_train'], data['y_train']\n",
    "X_val_RICE, y_val_RICE = data['X_val'], data['y_val']\n",
    "X_test_RICE, y_test_RICE = data['X_test'], data['y_test']\n",
    "n_class_RICE = len(np.unique(y_test_RICE))\n",
    "\n",
    "print(\"Number of train samples: \", X_train_RICE.shape[0])\n",
    "print(\"Number of val samples: \", X_val_RICE.shape[0])\n",
    "print(\"Number of test samples: \", X_test_RICE.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes how well your model performs using accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, y_test):\n",
    "    return np.sum(y_test == pred) / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according to the perceptron update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Perceptron classifier in the **models/perceptron.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Perceptron classifier class \n",
    "- The train function of the Perceptron class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 10.646\n",
      "Epoch 1 Accuracy 83.71\n",
      "Epoch 2 Accuracy 84.006\n",
      "Epoch 3 Accuracy 84.08200000000001\n",
      "Epoch 4 Accuracy 84.08200000000001\n",
      "Epoch 5 Accuracy 84.08200000000001\n",
      "Epoch 6 Accuracy 84.08200000000001\n",
      "Epoch 7 Accuracy 84.08200000000001\n",
      "Epoch 8 Accuracy 84.08200000000001\n",
      "Epoch 9 Accuracy 84.08200000000001\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "\n",
    "percept_fashion = Perceptron(n_class_fashion, lr, n_epochs)\n",
    "percept_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 84.082000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 82.020000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 81.880000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy, output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/perceptron_submission_fashion.csv', percept_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 54.779580240124645\n",
      "Epoch 1 Accuracy 94.94088534506461\n",
      "Epoch 2 Accuracy 99.8166987443864\n",
      "Epoch 3 Accuracy 99.89918430941252\n",
      "Epoch 4 Accuracy 99.89918430941252\n",
      "Epoch 5 Accuracy 99.89918430941252\n",
      "Epoch 6 Accuracy 99.89918430941252\n",
      "Epoch 7 Accuracy 99.89918430941252\n",
      "Epoch 8 Accuracy 99.89918430941252\n",
      "Epoch 9 Accuracy 99.89918430941252\n",
      "Epoch 10 Accuracy 99.89918430941252\n",
      "Epoch 11 Accuracy 99.89918430941252\n",
      "Epoch 12 Accuracy 99.89918430941252\n",
      "Epoch 13 Accuracy 99.89918430941252\n",
      "Epoch 14 Accuracy 99.89918430941252\n",
      "Epoch 15 Accuracy 99.89918430941252\n",
      "Epoch 16 Accuracy 99.89918430941252\n",
      "Epoch 17 Accuracy 99.89918430941252\n",
      "Epoch 18 Accuracy 99.89918430941252\n",
      "Epoch 19 Accuracy 99.89918430941252\n"
     ]
    }
   ],
   "source": [
    "lr = 0.3\n",
    "n_epochs = 20\n",
    "\n",
    "percept_RICE = Perceptron(n_class_RICE, lr, n_epochs)\n",
    "percept_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 99.899184\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 99.835029\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 99.835029\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will implement a \"soft margin\" SVM. In this formulation you will maximize the margin between positive and negative training examples and penalize margin violations using a hinge loss.\n",
    "\n",
    "We will optimize the SVM loss using SGD. This means you must compute the loss function with respect to model weights. You will use this gradient to update the model weights.\n",
    "\n",
    "SVM optimized with SGD has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Epochs** - similar to as defined above in Perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case it is a coefficient on the term which maximizes the margin. You could try different values. The default value is set to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the SVM using SGD in the **models/svm.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the SVM classifier class \n",
    "- The train function of the SVM class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 9.693999999999999\n",
      "Epoch 1 Accuracy 77.282\n",
      "Epoch 2 Accuracy 74.698\n",
      "Epoch 3 Accuracy 82.054\n",
      "Epoch 4 Accuracy 79.814\n",
      "Epoch 5 Accuracy 83.834\n",
      "Epoch 6 Accuracy 82.296\n",
      "Epoch 7 Accuracy 83.97\n",
      "Epoch 8 Accuracy 84.218\n",
      "Epoch 9 Accuracy 84.372\n",
      "Epoch 10 Accuracy 84.298\n",
      "Epoch 11 Accuracy 84.24000000000001\n",
      "Epoch 12 Accuracy 84.186\n",
      "Epoch 13 Accuracy 84.314\n",
      "Epoch 14 Accuracy 84.296\n",
      "Epoch 15 Accuracy 84.38600000000001\n",
      "Epoch 16 Accuracy 84.348\n",
      "Epoch 17 Accuracy 84.294\n",
      "Epoch 18 Accuracy 84.298\n",
      "Epoch 19 Accuracy 84.32600000000001\n",
      "Epoch 20 Accuracy 84.32\n",
      "Epoch 21 Accuracy 84.32\n",
      "Epoch 22 Accuracy 84.336\n",
      "Epoch 23 Accuracy 84.328\n",
      "Epoch 24 Accuracy 84.322\n",
      "Epoch 25 Accuracy 84.316\n",
      "Epoch 26 Accuracy 84.316\n",
      "Epoch 27 Accuracy 84.314\n",
      "Epoch 28 Accuracy 84.31\n",
      "Epoch 29 Accuracy 84.308\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "n_epochs = 30\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_fashion = SVM(n_class_fashion, lr, n_epochs, reg_const)\n",
    "svm_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 84.308000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 82.840000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 82.140000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/svm_submission_fashion.csv', svm_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 54.779580240124645\n",
      "Epoch 1 Accuracy 59.160480249289705\n",
      "Epoch 2 Accuracy 62.423242599211804\n",
      "Epoch 3 Accuracy 74.60361103473558\n",
      "Epoch 4 Accuracy 77.49977087343048\n",
      "Epoch 5 Accuracy 79.08532673448812\n",
      "Epoch 6 Accuracy 78.41627715149849\n",
      "Epoch 7 Accuracy 78.7278892860416\n",
      "Epoch 8 Accuracy 78.27880120978828\n",
      "Epoch 9 Accuracy 79.0944917972688\n",
      "Epoch 10 Accuracy 78.98451104390065\n",
      "Epoch 11 Accuracy 78.94785079277793\n",
      "Epoch 12 Accuracy 79.13115204839153\n",
      "Epoch 13 Accuracy 79.07616167170745\n",
      "Epoch 14 Accuracy 79.08532673448812\n",
      "Epoch 15 Accuracy 79.05783154614609\n",
      "Epoch 16 Accuracy 79.00284116946202\n",
      "Epoch 17 Accuracy 79.00284116946202\n",
      "Epoch 18 Accuracy 79.00284116946202\n",
      "Epoch 19 Accuracy 79.0120062322427\n",
      "Epoch 20 Accuracy 79.03950142058474\n",
      "Epoch 21 Accuracy 79.04866648336541\n",
      "Epoch 22 Accuracy 79.04866648336541\n",
      "Epoch 23 Accuracy 79.04866648336541\n",
      "Epoch 24 Accuracy 79.04866648336541\n",
      "Epoch 25 Accuracy 79.04866648336541\n",
      "Epoch 26 Accuracy 79.04866648336541\n",
      "Epoch 27 Accuracy 79.03033635780406\n",
      "Epoch 28 Accuracy 79.04866648336541\n",
      "Epoch 29 Accuracy 79.04866648336541\n",
      "Epoch 30 Accuracy 79.04866648336541\n",
      "Epoch 31 Accuracy 79.04866648336541\n",
      "Epoch 32 Accuracy 79.04866648336541\n",
      "Epoch 33 Accuracy 79.04866648336541\n",
      "Epoch 34 Accuracy 79.04866648336541\n",
      "Epoch 35 Accuracy 79.04866648336541\n",
      "Epoch 36 Accuracy 79.04866648336541\n",
      "Epoch 37 Accuracy 79.04866648336541\n",
      "Epoch 38 Accuracy 79.04866648336541\n",
      "Epoch 39 Accuracy 79.04866648336541\n",
      "Epoch 40 Accuracy 79.04866648336541\n",
      "Epoch 41 Accuracy 79.04866648336541\n",
      "Epoch 42 Accuracy 79.04866648336541\n",
      "Epoch 43 Accuracy 79.04866648336541\n",
      "Epoch 44 Accuracy 79.04866648336541\n",
      "Epoch 45 Accuracy 79.04866648336541\n",
      "Epoch 46 Accuracy 79.04866648336541\n",
      "Epoch 47 Accuracy 79.04866648336541\n",
      "Epoch 48 Accuracy 79.04866648336541\n",
      "Epoch 49 Accuracy 79.04866648336541\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "n_epochs = 50\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_RICE = SVM(n_class_RICE, lr, n_epochs, reg_const)\n",
    "svm_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 79.048666\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 78.581248\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 79.323618\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classifier (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, you will train a Softmax classifier. This classifier consists of a linear function of the input data followed by a softmax function which outputs a vector of dimension C (number of classes) for each data point. Each entry of the softmax output vector corresponds to a confidence in one of the C classes, and like a probability distribution, the entries of the output vector sum to 1. We use a cross-entropy loss on this sotmax output to train the model. \n",
    "\n",
    "Check the following link as an additional resource on softmax classification: http://cs231n.github.io/linear-classify/#softmax\n",
    "\n",
    "Once again we will train the classifier with SGD. This means you need to compute the gradients of the softmax cross-entropy loss function according to the weights and update the weights using this gradient. Check the following link to help with implementing the gradient updates: https://deepnotes.io/softmax-crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax classifier has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - As above, this controls how much the model weights are updated with respect to their gradient.\n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case, we minimize the L2 norm of the model weights as regularization, so the regularization constant is a coefficient on the L2 norm in the combined cross-entropy and regularization objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement a softmax classifier using SGD in the **models/softmax.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Softmax classifier class \n",
    "- The train function of the Softmax class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 6.39\n",
      "Epoch 1 Accuracy 75.994\n",
      "Epoch 2 Accuracy 78.276\n",
      "Epoch 3 Accuracy 78.798\n",
      "Epoch 4 Accuracy 79.994\n",
      "Epoch 5 Accuracy 80.05\n",
      "Epoch 6 Accuracy 81.186\n",
      "Epoch 7 Accuracy 79.10199999999999\n",
      "Epoch 8 Accuracy 81.462\n",
      "Epoch 9 Accuracy 82.592\n",
      "Epoch 10 Accuracy 78.572\n",
      "Epoch 11 Accuracy 82.238\n",
      "Epoch 12 Accuracy 80.822\n",
      "Epoch 13 Accuracy 81.734\n",
      "Epoch 14 Accuracy 85.356\n",
      "Epoch 15 Accuracy 83.084\n",
      "Epoch 16 Accuracy 82.988\n",
      "Epoch 17 Accuracy 83.248\n",
      "Epoch 18 Accuracy 82.35\n",
      "Epoch 19 Accuracy 82.462\n",
      "Epoch 20 Accuracy 81.41000000000001\n",
      "Epoch 21 Accuracy 78.676\n",
      "Epoch 22 Accuracy 77.53999999999999\n",
      "Epoch 23 Accuracy 82.446\n",
      "Epoch 24 Accuracy 82.91\n",
      "Epoch 25 Accuracy 83.978\n",
      "Epoch 26 Accuracy 83.8\n",
      "Epoch 27 Accuracy 82.048\n",
      "Epoch 28 Accuracy 77.84400000000001\n",
      "Epoch 29 Accuracy 82.734\n",
      "Epoch 30 Accuracy 76.94\n",
      "Epoch 31 Accuracy 84.3\n",
      "Epoch 32 Accuracy 83.364\n",
      "Epoch 33 Accuracy 85.112\n",
      "Epoch 34 Accuracy 85.504\n",
      "Epoch 35 Accuracy 77.45\n",
      "Epoch 36 Accuracy 80.444\n",
      "Epoch 37 Accuracy 79.164\n",
      "Epoch 38 Accuracy 81.498\n",
      "Epoch 39 Accuracy 83.492\n",
      "Epoch 40 Accuracy 76.86\n",
      "Epoch 41 Accuracy 82.812\n",
      "Epoch 42 Accuracy 82.798\n",
      "Epoch 43 Accuracy 85.524\n",
      "Epoch 44 Accuracy 82.95\n",
      "Epoch 45 Accuracy 83.366\n",
      "Epoch 46 Accuracy 84.574\n",
      "Epoch 47 Accuracy 84.922\n",
      "Epoch 48 Accuracy 85.91\n",
      "Epoch 49 Accuracy 85.658\n",
      "Epoch 50 Accuracy 85.48\n",
      "Epoch 51 Accuracy 84.084\n",
      "Epoch 52 Accuracy 83.692\n",
      "Epoch 53 Accuracy 83.096\n",
      "Epoch 54 Accuracy 86.22800000000001\n",
      "Epoch 55 Accuracy 84.77\n",
      "Epoch 56 Accuracy 85.464\n",
      "Epoch 57 Accuracy 85.58\n",
      "Epoch 58 Accuracy 81.77600000000001\n",
      "Epoch 59 Accuracy 86.65\n",
      "Epoch 60 Accuracy 85.992\n",
      "Epoch 61 Accuracy 86.824\n",
      "Epoch 62 Accuracy 86.92\n",
      "Epoch 63 Accuracy 87.238\n",
      "Epoch 64 Accuracy 87.24\n",
      "Epoch 65 Accuracy 87.148\n",
      "Epoch 66 Accuracy 85.274\n",
      "Epoch 67 Accuracy 87.16000000000001\n",
      "Epoch 68 Accuracy 88.016\n",
      "Epoch 69 Accuracy 86.982\n",
      "Epoch 70 Accuracy 86.19\n",
      "Epoch 71 Accuracy 87.786\n",
      "Epoch 72 Accuracy 87.646\n",
      "Epoch 73 Accuracy 88.05199999999999\n",
      "Epoch 74 Accuracy 87.31400000000001\n",
      "Epoch 75 Accuracy 87.96199999999999\n",
      "Epoch 76 Accuracy 87.64999999999999\n",
      "Epoch 77 Accuracy 87.28\n",
      "Epoch 78 Accuracy 88.008\n",
      "Epoch 79 Accuracy 87.972\n",
      "Epoch 80 Accuracy 87.756\n",
      "Epoch 81 Accuracy 88.064\n",
      "Epoch 82 Accuracy 88.03999999999999\n",
      "Epoch 83 Accuracy 88.05\n",
      "Epoch 84 Accuracy 87.688\n",
      "Epoch 85 Accuracy 88.168\n",
      "Epoch 86 Accuracy 88.03\n",
      "Epoch 87 Accuracy 87.66199999999999\n",
      "Epoch 88 Accuracy 88.108\n",
      "Epoch 89 Accuracy 88.212\n",
      "Epoch 90 Accuracy 88.13\n",
      "Epoch 91 Accuracy 88.32\n",
      "Epoch 92 Accuracy 88.22\n",
      "Epoch 93 Accuracy 88.276\n",
      "Epoch 94 Accuracy 88.0\n",
      "Epoch 95 Accuracy 88.39399999999999\n",
      "Epoch 96 Accuracy 88.164\n",
      "Epoch 97 Accuracy 87.83800000000001\n",
      "Epoch 98 Accuracy 88.228\n",
      "Epoch 99 Accuracy 88.03800000000001\n",
      "Epoch 100 Accuracy 88.354\n",
      "Epoch 101 Accuracy 88.348\n",
      "Epoch 102 Accuracy 88.22\n",
      "Epoch 103 Accuracy 88.262\n",
      "Epoch 104 Accuracy 88.292\n",
      "Epoch 105 Accuracy 88.30799999999999\n",
      "Epoch 106 Accuracy 88.318\n",
      "Epoch 107 Accuracy 88.304\n",
      "Epoch 108 Accuracy 88.31599999999999\n",
      "Epoch 109 Accuracy 88.27000000000001\n",
      "Epoch 110 Accuracy 88.366\n",
      "Epoch 111 Accuracy 88.372\n",
      "Epoch 112 Accuracy 88.372\n",
      "Epoch 113 Accuracy 88.31599999999999\n",
      "Epoch 114 Accuracy 88.336\n",
      "Epoch 115 Accuracy 88.402\n",
      "Epoch 116 Accuracy 88.426\n",
      "Epoch 117 Accuracy 88.412\n",
      "Epoch 118 Accuracy 88.426\n",
      "Epoch 119 Accuracy 88.20400000000001\n",
      "Epoch 120 Accuracy 88.408\n",
      "Epoch 121 Accuracy 88.354\n",
      "Epoch 122 Accuracy 88.432\n",
      "Epoch 123 Accuracy 88.388\n",
      "Epoch 124 Accuracy 88.46000000000001\n",
      "Epoch 125 Accuracy 88.332\n",
      "Epoch 126 Accuracy 88.376\n",
      "Epoch 127 Accuracy 88.434\n",
      "Epoch 128 Accuracy 88.478\n",
      "Epoch 129 Accuracy 88.446\n",
      "Epoch 130 Accuracy 88.378\n",
      "Epoch 131 Accuracy 88.426\n",
      "Epoch 132 Accuracy 88.472\n",
      "Epoch 133 Accuracy 88.414\n",
      "Epoch 134 Accuracy 88.466\n",
      "Epoch 135 Accuracy 88.44\n",
      "Epoch 136 Accuracy 88.416\n",
      "Epoch 137 Accuracy 88.498\n",
      "Epoch 138 Accuracy 88.426\n",
      "Epoch 139 Accuracy 88.442\n",
      "Epoch 140 Accuracy 88.414\n",
      "Epoch 141 Accuracy 88.446\n",
      "Epoch 142 Accuracy 88.412\n",
      "Epoch 143 Accuracy 88.426\n",
      "Epoch 144 Accuracy 88.44999999999999\n",
      "Epoch 145 Accuracy 88.442\n",
      "Epoch 146 Accuracy 88.456\n",
      "Epoch 147 Accuracy 88.474\n",
      "Epoch 148 Accuracy 88.414\n",
      "Epoch 149 Accuracy 88.416\n",
      "Epoch 150 Accuracy 88.402\n",
      "Epoch 151 Accuracy 88.414\n",
      "Epoch 152 Accuracy 88.42\n",
      "Epoch 153 Accuracy 88.426\n",
      "Epoch 154 Accuracy 88.442\n",
      "Epoch 155 Accuracy 88.46199999999999\n",
      "Epoch 156 Accuracy 88.454\n",
      "Epoch 157 Accuracy 88.428\n",
      "Epoch 158 Accuracy 88.434\n",
      "Epoch 159 Accuracy 88.472\n",
      "Epoch 160 Accuracy 88.464\n",
      "Epoch 161 Accuracy 88.44800000000001\n",
      "Epoch 162 Accuracy 88.41\n",
      "Epoch 163 Accuracy 88.414\n",
      "Epoch 164 Accuracy 88.41799999999999\n",
      "Epoch 165 Accuracy 88.444\n",
      "Epoch 166 Accuracy 88.4\n",
      "Epoch 167 Accuracy 88.41799999999999\n",
      "Epoch 168 Accuracy 88.412\n",
      "Epoch 169 Accuracy 88.416\n",
      "Epoch 170 Accuracy 88.40400000000001\n",
      "Epoch 171 Accuracy 88.442\n",
      "Epoch 172 Accuracy 88.42\n",
      "Epoch 173 Accuracy 88.428\n",
      "Epoch 174 Accuracy 88.456\n",
      "Epoch 175 Accuracy 88.426\n",
      "Epoch 176 Accuracy 88.432\n",
      "Epoch 177 Accuracy 88.44\n",
      "Epoch 178 Accuracy 88.426\n",
      "Epoch 179 Accuracy 88.436\n",
      "Epoch 180 Accuracy 88.438\n",
      "Epoch 181 Accuracy 88.438\n",
      "Epoch 182 Accuracy 88.436\n",
      "Epoch 183 Accuracy 88.432\n",
      "Epoch 184 Accuracy 88.438\n",
      "Epoch 185 Accuracy 88.44\n",
      "Epoch 186 Accuracy 88.44\n",
      "Epoch 187 Accuracy 88.436\n",
      "Epoch 188 Accuracy 88.436\n",
      "Epoch 189 Accuracy 88.42999999999999\n",
      "Epoch 190 Accuracy 88.42999999999999\n",
      "Epoch 191 Accuracy 88.432\n",
      "Epoch 192 Accuracy 88.436\n",
      "Epoch 193 Accuracy 88.428\n",
      "Epoch 194 Accuracy 88.432\n",
      "Epoch 195 Accuracy 88.436\n",
      "Epoch 196 Accuracy 88.432\n",
      "Epoch 197 Accuracy 88.436\n",
      "Epoch 198 Accuracy 88.436\n",
      "Epoch 199 Accuracy 88.438\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "n_epochs = 200\n",
    "reg_const = 1\n",
    "\n",
    "softmax_fashion = Softmax(n_class_fashion, lr, n_epochs, reg_const)\n",
    "softmax_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 88.436000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 84.540000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 83.530000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/softmax_submission_fashion.csv', softmax_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 47.28255888552837\n",
      "Epoch 1 Accuracy 45.220419759875355\n",
      "Epoch 2 Accuracy 54.779580240124645\n",
      "Epoch 3 Accuracy 54.779580240124645\n",
      "Epoch 4 Accuracy 45.220419759875355\n",
      "Epoch 5 Accuracy 45.220419759875355\n",
      "Epoch 6 Accuracy 45.220419759875355\n",
      "Epoch 7 Accuracy 60.141141966822474\n",
      "Epoch 8 Accuracy 45.220419759875355\n",
      "Epoch 9 Accuracy 54.779580240124645\n",
      "Epoch 10 Accuracy 64.89780954999543\n",
      "Epoch 11 Accuracy 45.220419759875355\n",
      "Epoch 12 Accuracy 76.711575474292\n",
      "Epoch 13 Accuracy 54.779580240124645\n",
      "Epoch 14 Accuracy 45.220419759875355\n",
      "Epoch 15 Accuracy 75.55677756392632\n",
      "Epoch 16 Accuracy 76.253322335258\n",
      "Epoch 17 Accuracy 45.220419759875355\n",
      "Epoch 18 Accuracy 56.29181559893686\n",
      "Epoch 19 Accuracy 73.71459994500962\n",
      "Epoch 20 Accuracy 56.695078361286775\n",
      "Epoch 21 Accuracy 45.220419759875355\n",
      "Epoch 22 Accuracy 78.40711208871781\n",
      "Epoch 23 Accuracy 78.33379158647237\n",
      "Epoch 24 Accuracy 60.05865640179635\n",
      "Epoch 25 Accuracy 54.779580240124645\n",
      "Epoch 26 Accuracy 51.76427458528091\n",
      "Epoch 27 Accuracy 45.220419759875355\n",
      "Epoch 28 Accuracy 45.220419759875355\n",
      "Epoch 29 Accuracy 45.220419759875355\n",
      "Epoch 30 Accuracy 45.220419759875355\n",
      "Epoch 31 Accuracy 52.01173128035927\n",
      "Epoch 32 Accuracy 72.61479241132803\n",
      "Epoch 33 Accuracy 45.220419759875355\n",
      "Epoch 34 Accuracy 57.61158463935479\n",
      "Epoch 35 Accuracy 57.061680872513975\n",
      "Epoch 36 Accuracy 45.220419759875355\n",
      "Epoch 37 Accuracy 67.61066813307671\n",
      "Epoch 38 Accuracy 54.779580240124645\n",
      "Epoch 39 Accuracy 77.82054807075428\n",
      "Epoch 40 Accuracy 59.618733388323705\n",
      "Epoch 41 Accuracy 79.15864723673357\n",
      "Epoch 42 Accuracy 45.220419759875355\n",
      "Epoch 43 Accuracy 55.21950325359729\n",
      "Epoch 44 Accuracy 55.622766015947214\n",
      "Epoch 45 Accuracy 76.54660434423975\n",
      "Epoch 46 Accuracy 71.78993676106681\n",
      "Epoch 47 Accuracy 50.09623315919715\n",
      "Epoch 48 Accuracy 63.46805975620933\n",
      "Epoch 49 Accuracy 63.633030886261565\n",
      "Epoch 50 Accuracy 55.476125011456325\n",
      "Epoch 51 Accuracy 66.75831729447347\n",
      "Epoch 52 Accuracy 56.695078361286775\n",
      "Epoch 53 Accuracy 55.41196957199157\n",
      "Epoch 54 Accuracy 68.06892127211071\n",
      "Epoch 55 Accuracy 66.92328842452571\n",
      "Epoch 56 Accuracy 50.2520392264687\n",
      "Epoch 57 Accuracy 69.41618550087068\n",
      "Epoch 58 Accuracy 60.59939510585648\n",
      "Epoch 59 Accuracy 72.09238383282926\n",
      "Epoch 60 Accuracy 50.78361286774814\n",
      "Epoch 61 Accuracy 74.3286591513152\n",
      "Epoch 62 Accuracy 57.12583631197874\n",
      "Epoch 63 Accuracy 59.04133443314087\n",
      "Epoch 64 Accuracy 72.45898634405646\n",
      "Epoch 65 Accuracy 49.39968838786546\n",
      "Epoch 66 Accuracy 70.6443039134818\n",
      "Epoch 67 Accuracy 63.183942810008254\n",
      "Epoch 68 Accuracy 63.733846576849054\n",
      "Epoch 69 Accuracy 74.01704701677207\n",
      "Epoch 70 Accuracy 79.25946292732105\n",
      "Epoch 71 Accuracy 77.72889744294748\n",
      "Epoch 72 Accuracy 58.12482815507286\n",
      "Epoch 73 Accuracy 62.20328109247548\n",
      "Epoch 74 Accuracy 56.319310787278894\n",
      "Epoch 75 Accuracy 72.20236458619742\n",
      "Epoch 76 Accuracy 76.03336082852168\n",
      "Epoch 77 Accuracy 70.66263403904317\n",
      "Epoch 78 Accuracy 74.69526166254239\n",
      "Epoch 79 Accuracy 75.87755476125011\n",
      "Epoch 80 Accuracy 74.02621207955275\n",
      "Epoch 81 Accuracy 50.18788378700394\n",
      "Epoch 82 Accuracy 72.26652002566217\n",
      "Epoch 83 Accuracy 75.45596187333882\n",
      "Epoch 84 Accuracy 77.01402254605443\n",
      "Epoch 85 Accuracy 76.16167170745119\n",
      "Epoch 86 Accuracy 79.24113280175969\n",
      "Epoch 87 Accuracy 78.94785079277793\n",
      "Epoch 88 Accuracy 74.72275685088444\n",
      "Epoch 89 Accuracy 70.58014847401705\n",
      "Epoch 90 Accuracy 79.04866648336541\n",
      "Epoch 91 Accuracy 74.87856291815599\n",
      "Epoch 92 Accuracy 48.60232792594629\n",
      "Epoch 93 Accuracy 71.7991018238475\n",
      "Epoch 94 Accuracy 74.28283383741179\n",
      "Epoch 95 Accuracy 59.28879112821923\n",
      "Epoch 96 Accuracy 73.18302630373019\n",
      "Epoch 97 Accuracy 73.9528915773073\n",
      "Epoch 98 Accuracy 56.56676748235725\n",
      "Epoch 99 Accuracy 63.596370635138854\n",
      "Epoch 100 Accuracy 73.70543488222894\n",
      "Epoch 101 Accuracy 78.09549995417468\n",
      "Epoch 102 Accuracy 79.25029786454037\n",
      "Epoch 103 Accuracy 67.26239574741088\n",
      "Epoch 104 Accuracy 79.67189075245166\n",
      "Epoch 105 Accuracy 77.11483823664193\n",
      "Epoch 106 Accuracy 65.94262670699294\n",
      "Epoch 107 Accuracy 75.29099074328659\n",
      "Epoch 108 Accuracy 60.26028778297131\n",
      "Epoch 109 Accuracy 61.79085326734488\n",
      "Epoch 110 Accuracy 74.98854367152416\n",
      "Epoch 111 Accuracy 61.77252314178352\n",
      "Epoch 112 Accuracy 69.97525433049216\n",
      "Epoch 113 Accuracy 78.28796627256897\n",
      "Epoch 114 Accuracy 79.58024012464485\n",
      "Epoch 115 Accuracy 75.43763174777747\n",
      "Epoch 116 Accuracy 80.13930895426634\n",
      "Epoch 117 Accuracy 78.76454953716433\n",
      "Epoch 118 Accuracy 58.922188616992024\n",
      "Epoch 119 Accuracy 71.45999450096234\n",
      "Epoch 120 Accuracy 79.24113280175969\n",
      "Epoch 121 Accuracy 58.75721748693978\n",
      "Epoch 122 Accuracy 78.88369535331317\n",
      "Epoch 123 Accuracy 79.48858949683806\n",
      "Epoch 124 Accuracy 63.550545321235454\n",
      "Epoch 125 Accuracy 78.58124828155073\n",
      "Epoch 126 Accuracy 61.28677481440747\n",
      "Epoch 127 Accuracy 68.1697369626982\n",
      "Epoch 128 Accuracy 79.35111355512785\n",
      "Epoch 129 Accuracy 80.8450187883787\n",
      "Epoch 130 Accuracy 70.31436165337732\n",
      "Epoch 131 Accuracy 67.41820181468243\n",
      "Epoch 132 Accuracy 79.2869581156631\n",
      "Epoch 133 Accuracy 76.4366235908716\n",
      "Epoch 134 Accuracy 72.0190633305838\n",
      "Epoch 135 Accuracy 61.66254238841537\n",
      "Epoch 136 Accuracy 72.81642379250299\n",
      "Epoch 137 Accuracy 67.83062963981304\n",
      "Epoch 138 Accuracy 54.128860782696364\n",
      "Epoch 139 Accuracy 80.95499954174686\n",
      "Epoch 140 Accuracy 74.89689304371736\n",
      "Epoch 141 Accuracy 71.73494638438274\n",
      "Epoch 142 Accuracy 73.36632755934377\n",
      "Epoch 143 Accuracy 76.64742003482723\n",
      "Epoch 144 Accuracy 72.29401521400422\n",
      "Epoch 145 Accuracy 72.58729722298598\n",
      "Epoch 146 Accuracy 63.00064155439464\n",
      "Epoch 147 Accuracy 69.84694345156265\n",
      "Epoch 148 Accuracy 71.74411144716342\n",
      "Epoch 149 Accuracy 72.3948309045917\n",
      "Epoch 150 Accuracy 60.86518192649619\n",
      "Epoch 151 Accuracy 77.27064430391349\n",
      "Epoch 152 Accuracy 78.0405095774906\n",
      "Epoch 153 Accuracy 76.88571166712492\n",
      "Epoch 154 Accuracy 85.23508386032445\n",
      "Epoch 155 Accuracy 84.91430666300064\n",
      "Epoch 156 Accuracy 67.5190175052699\n",
      "Epoch 157 Accuracy 56.56676748235725\n",
      "Epoch 158 Accuracy 76.95903216937036\n",
      "Epoch 159 Accuracy 88.2870497662909\n",
      "Epoch 160 Accuracy 65.14526624507377\n",
      "Epoch 161 Accuracy 85.14343323251764\n",
      "Epoch 162 Accuracy 88.67198240307947\n",
      "Epoch 163 Accuracy 77.59142150123728\n",
      "Epoch 164 Accuracy 93.53863073962057\n",
      "Epoch 165 Accuracy 83.6495279992668\n",
      "Epoch 166 Accuracy 99.18430941251948\n",
      "Epoch 167 Accuracy 99.84419393272844\n",
      "Epoch 168 Accuracy 99.92667949775455\n",
      "Epoch 169 Accuracy 99.78003849326367\n",
      "Epoch 170 Accuracy 99.89918430941252\n",
      "Epoch 171 Accuracy 99.53258179818532\n",
      "Epoch 172 Accuracy 99.44093117037852\n",
      "Epoch 173 Accuracy 99.79836861882504\n",
      "Epoch 174 Accuracy 99.71588305379892\n",
      "Epoch 175 Accuracy 99.85335899550913\n",
      "Epoch 176 Accuracy 99.89001924663185\n",
      "Epoch 177 Accuracy 99.83502886994776\n",
      "Epoch 178 Accuracy 99.89001924663185\n",
      "Epoch 179 Accuracy 99.84419393272844\n",
      "Epoch 180 Accuracy 99.88085418385117\n",
      "Epoch 181 Accuracy 99.91751443497388\n",
      "Epoch 182 Accuracy 99.89918430941252\n",
      "Epoch 183 Accuracy 99.89918430941252\n",
      "Epoch 184 Accuracy 99.9083493721932\n",
      "Epoch 185 Accuracy 99.91751443497388\n",
      "Epoch 186 Accuracy 99.87168912107049\n",
      "Epoch 187 Accuracy 99.9083493721932\n",
      "Epoch 188 Accuracy 99.86252405828981\n",
      "Epoch 189 Accuracy 99.89918430941252\n",
      "Epoch 190 Accuracy 99.84419393272844\n",
      "Epoch 191 Accuracy 99.89918430941252\n",
      "Epoch 192 Accuracy 99.89001924663185\n",
      "Epoch 193 Accuracy 99.84419393272844\n",
      "Epoch 194 Accuracy 99.74337824214096\n",
      "Epoch 195 Accuracy 99.85335899550913\n",
      "Epoch 196 Accuracy 99.9083493721932\n",
      "Epoch 197 Accuracy 99.89918430941252\n",
      "Epoch 198 Accuracy 99.9083493721932\n",
      "Epoch 199 Accuracy 99.9083493721932\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 200\n",
    "reg_const = 1\n",
    "\n",
    "softmax_RICE = Softmax(n_class_RICE, lr, n_epochs, reg_const)\n",
    "softmax_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 99.908349\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 99.835029\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 99.862524\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Classifier has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Threshold** - The decision boundary of the classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Logistic Classifier in the **models/logistic.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Logistic classifier class \n",
    "- The train function of the Logistic class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy 54.779580240124645\n",
      "Epoch 1 Accuracy 69.36119512418661\n",
      "Epoch 2 Accuracy 71.91824763999634\n",
      "Epoch 3 Accuracy 68.49967922280268\n",
      "Epoch 4 Accuracy 91.74227843460727\n",
      "Epoch 5 Accuracy 78.38878196315645\n",
      "Epoch 6 Accuracy 94.84923471725781\n",
      "Epoch 7 Accuracy 97.35129685638346\n",
      "Epoch 8 Accuracy 95.8665566859133\n",
      "Epoch 9 Accuracy 98.47859957840711\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.2\n",
    "n_epochs = 10\n",
    "threshold = 0\n",
    "\n",
    "y_train_RICE = np.where(y_train_RICE == 0, -1, y_train_RICE)\n",
    "\n",
    "lr = Logistic(learning_rate, n_epochs, threshold)\n",
    "lr.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 99.624232\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 99.615067\n"
     ]
    }
   ],
   "source": [
    "y_val_RICE = np.where(y_val_RICE == 0, -1, y_val_RICE)\n",
    "pred_lr = lr.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 99.642563\n"
     ]
    }
   ],
   "source": [
    "y_test_RICE = np.where(y_test_RICE == 0, -1, y_test_RICE)\n",
    "pred_lr = lr.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
